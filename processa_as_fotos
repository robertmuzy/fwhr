import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import dlib
import cv2
from PIL import Image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
from sklearn.model_selection import train_test_split

# Define o caminho para a pasta onde as imagens originais estão armazenadas
input_path = Path('/EXECUCOMP/Fotos')

# Define o caminho para a pasta onde as imagens processadas serão salvas
output_path = Path('/EXECUCOMP/Fotos_processadas')

# Cria a pasta de saída se ela não existir
output_path.mkdir(parents=True, exist_ok=True)

# Lista para armazenar o resultado do processamento de cada arquivo
processing_results = []
# Função para processar as imagens
def process_image(file_path):
    try:
        # Carrega a imagem usando OpenCV
        image = cv2.imread(str(file_path))
        
        # Converte a imagem para escala de cinza
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Usa a detecção de face do OpenCV para encontrar e recortar a face
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5)
        
        # Se nenhuma face for encontrada, continua para a próxima imagem
        if len(faces) == 0:
            raise ValueError("Nenhuma face encontrada.")
        
        # Recorta a imagem para o primeiro rosto encontrado (poderia ser ajustado para lidar com múltiplas faces)
        for (x, y, w, h) in faces:
            face = image[y:y+h, x:x+w]
            break
        
        # Salva a imagem processada na pasta de saída
        processed_file_path = output_path / file_path.name
        cv2.imwrite(str(processed_file_path), face)
        
        # Retorna o nome do arquivo e o sucesso do processamento
        return (file_path.name, "Sucesso")
    except Exception as e:
        # Retorna o nome do arquivo e a mensagem de erro
        return (file_path.name, str(e))

# Processa cada arquivo de imagem na pasta de entrada
for file_name in os.listdir(input_path):
    file_path = input_path / file_name
    if file_path.suffix.lower() == '.jpg':
        result = process_image(file_path)
        processing_results.append(result)

# Cria um DataFrame com os resultados do processamento
df_processing_results = pd.DataFrame(processing_results, columns=['Nome do Arquivo', 'Resultado'])

# Exibe o DataFrame com os resultados
df_processing_results.head()

# Definir o caminho para o detector de landmarks
predictor_path = '/EXECUCOMP/shape_predictor_68_face_landmarks.dat'
predictor = dlib.shape_predictor(predictor_path)

# Função para calcular a largura do rosto
def calculate_width(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    detector = dlib.get_frontal_face_detector()
    faces = detector(gray)
    if len(faces) > 0:
        face = faces[0]
        landmarks = predictor(gray, face)
        width = np.linalg.norm(np.array([landmarks.part(0).x, landmarks.part(0).y]) - 
                               np.array([landmarks.part(16).x, landmarks.part(16).y]))
        return width
    else:
        return None

def preprocess_image(image_path, target_size=(128, 128)):
    """
    Carrega uma imagem, redimensiona para o tamanho alvo e normaliza os valores dos pixels.

    :param image_path: Caminho para a imagem.
    :param target_size: Uma tupla (altura, largura) para o tamanho alvo da imagem.
    :return: Imagem pré-processada.
    """
    # Carregar a imagem
    img = cv2.imread(image_path)
    
    # Verificar se a imagem foi carregada corretamente
    if img is None:
        print(f"Erro ao carregar a imagem: {image_path}")
        return None
    
    # Redimensionar a imagem para o tamanho alvo
    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)
    
    # Normalizar os valores dos pixels (0-255 para 0-1)
    img_normalized = img_resized / 255.0
    
    return img_normalized

# Preparar os dados
input_images = []
output_widths = []

# Caminhos para as pastas de entrada e saída
input_dir = '/EXECUCOMP/dataset/input'
output_dir = '/EXECUCOMP/dataset/output'

# Processar as imagens
for i in range(1, 11):  # Para 10 fotos
    base_name = f"{i:03d}"
    output_image_path = os.path.join(output_dir, base_name + '.jpg')
    output_width = calculate_width(output_image_path)
    if output_width is not None:
        for pose in ['dir1', 'dir2', 'esq1', 'esq2']:
            input_image_path = os.path.join(input_dir, pose + base_name + '.jpg')
            # Aqui você deve adicionar o código para carregar e preprocessar a imagem de entrada
            # Por exemplo, redimensionar a imagem para um tamanho comum, normalizar, etc.
            input_image = preprocess_image(input_image_path)
            input_images.append(input_image)
            output_widths.append(output_width)

# Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(input_images, output_widths, test_size=0.2)

# Definir as dimensões da imagem para o modelo
altura_imagem, largura_imagem = 128, 128  # ou o tamanho que você usou no preprocessamento
canais = 3  # Para imagens coloridas no formato RGB

# Construir o modelo
model = Sequential([
     Conv2D(32, (3, 3), activation='relu', input_shape=(altura_imagem, largura_imagem, canais)),
     MaxPooling2D((2, 2)),
     Flatten(),
     Dense(64, activation='relu'),
     Dense(1)  # Saída: largura prevista
])

# Compilar o modelo
model.compile(optimizer='adam', loss='mean_squared_error')

# Treinar o modelo
model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

def preprocess_image(image_path, target_size=(128, 128)):
    # Carregar a imagem
    img = cv2.imread(image_path)
    if img is None:
        print(f"Erro ao carregar a imagem: {image_path}")
        return None
    
    # Redimensionar a imagem para o tamanho alvo
    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)
    
    # Normalizar os valores dos pixels
    img_normalized = img_resized / 255.0
    
    return img_normalized

def process_and_save_images(input_dir, output_dir, processed_dir, target_size=(128, 128)):
    # Verificar e criar a pasta processadas, se necessário
    if not os.path.exists(processed_dir):
        os.makedirs(processed_dir)

    # Processar as imagens de input
    for filename in os.listdir(input_dir):
        file_path = os.path.join(input_dir, filename)
        processed_image = preprocess_image(file_path, target_size)
        if processed_image is not None:
            # Salvar a imagem processada
            save_path = os.path.join(processed_dir, 'input_' + filename)
            cv2.imwrite(save_path, processed_image * 255)  # Reescalando ao salvar

    # Processar as imagens de output
    for filename in os.listdir(output_dir):
        file_path = os.path.join(output_dir, filename)
        processed_image = preprocess_image(file_path, target_size)
        if processed_image is not None:
            # Salvar a imagem processada
            save_path = os.path.join(processed_dir, 'output_' + filename)
            cv2.imwrite(save_path, processed_image * 255)  # Reescalando ao salvar

# Caminhos para as pastas de entrada e saída
input_dir = '/EXECUCOMP/dataset/input'
output_dir = '/EXECUCOMP/dataset/output'
processed_dir = '/EXECUCOMP/dataset/processed'

process_and_save_images(input_dir, output_dir, processed_dir)

# Testar o carregamento das imagens processadas
for filename in os.listdir(processed_dir):
    processed_image_path = os.path.join(processed_dir, filename)
    img = cv2.imread(processed_image_path)
    if img is None:
        print(f"Erro ao carregar a imagem processada: {processed_image_path}")
    else:
        print(f"Imagem processada carregada com sucesso: {processed_image_path}")

# Inicializar o detector de landmarks
predictor_path = '/EXECUCOMP/shape_predictor_68_face_landmarks.dat'
predictor = dlib.shape_predictor(predictor_path)
detector = dlib.get_frontal_face_detector()

# Função para calcular largura e altura do rosto
def calculate_face_dimensions(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)
    if len(faces) > 0:
        face = faces[0]
        landmarks = predictor(gray, face)
        width = np.linalg.norm(np.array([landmarks.part(0).x, landmarks.part(0).y]) - 
                               np.array([landmarks.part(16).x, landmarks.part(16).y]))
        height = np.linalg.norm(np.array([landmarks.part(27).x, landmarks.part(27).y]) - 
                                np.array([landmarks.part(51).x, landmarks.part(51).y]))
        return width, height, landmarks
    else:
        return None, None, None

# Processar imagens e coletar dados
data = []
for filename in os.listdir(processed_dir):
    if filename.endswith(".jpg"):
        img_path = os.path.join(processed_dir, filename)
        img = cv2.imread(img_path)
        
        if img is not None:
            width, height, landmarks = calculate_face_dimensions(img)
            if width is not None and height is not None:
                fwhr = width / height
                data.append({'File': filename, 'Height': height, 'Width': width, 'fWHR': fwhr})
                
                # Desenhar retângulo
                cv2.rectangle(img, (landmarks.part(0).x, landmarks.part(27).y), 
                              (landmarks.part(16).x, landmarks.part(51).y), (0, 255, 0), 2)
                
                # Exibir imagem
                plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                plt.title(f"{filename} - fWHR: {fwhr:.2f}")
                plt.axis('off')
                plt.show()

# Criar DataFrame e exibir
df = pd.DataFrame(data)
print(df)
